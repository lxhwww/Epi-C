# -*- coding: utf-8 -*-
"""cMet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/114YPAXmu39MCxG4EBbHSd5nWgzsSEEDv
"""

# from google.colab import drive
# drive.mount('/content/gdrive')



#Imports
import xenaPython as xena
from statistics import median, mean
import numpy as np 
import matplotlib.pyplot as plt 
import pandas as pd 
from sklearn.impute import SimpleImputer 
from sklearn import svm
from sklearn.metrics import accuracy_score, roc_auc_score, f1_score
from sklearn.ensemble import BaggingClassifier, RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from imblearn.ensemble import BalancedBaggingClassifier, RUSBoostClassifier
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split, KFold, cross_val_score, StratifiedKFold
import seaborn as sns
import warnings
from pylab import rcParams
from scipy.stats import f_oneway
from scipy.stats import ttest_ind
from collections import Counter
print( "--- Imports Successful ---")

#Getting Data
def get_samples(hub_name, data_set_name, no_of_samples):
  samples=xena.dataset_samples (hub, data_set_name,no_of_samples) # list of all the samples
  return samples
def get_features(hub_name, data_set_name):
  features=xena.dataset_field (hub, data_set_name)  # list of all the cpg markers in order
  return features
def get_data(hub_name, data_set_name, samples, features): 
  data=xena.dataset_probe_values(hub_name, data_set_name, samples, features)[1] # 2d list with 1st list --> values of first cpg marker
  data= list(map(list, zip(*data)))
  print( "--- Finished Fetching Data ---")

  return data
def get_label(hub_name, data_set_name, samples, phenotype):
  label=xena.dataset_probe_values(hub_name, data_set_name, samples, [phenotype])[1][0]  # list with stages
  return label

# Handling Missing Values
  # There were 28 missing labels. Since it was a small number the rows were removed
def handling_missing_values(d, stages, data, samples):
  l=[]
  for i in range(len(stages)):
    if stages[i]=='NaN' or stages[i]==0:
      l.append(i)
    else:
      stages[i]=d[str(stages[i])]
  l.sort(reverse=True)
  for i in l:
    stages.pop(i)
    data.pop(i)
    samples.pop(i)
  data=imputing(data)
  print( "--- Data Pre-Processing Completed ---")

  return (stages, data, samples)

def imputing(data):
  imputer = SimpleImputer(missing_values=np.nan, strategy='mean')
  imputer.fit(data) 
  data=imputer.transform(data)
  return data

#Models for training

def svm_model(X, y, sf, prediction_dict):
	auc=[]
	accu=[]
	f1=[]
	for train_ix , test_ix in sf.split(X, y):
		train_x, test_x = X[train_ix], X[test_ix]
		train_y, test_y = y[train_ix], y[test_ix]
		clf=svm.SVC()
		oversample=SMOTE()
		train_x,train_y=oversample.fit_resample(train_x, train_y)
		clf.fit(train_x, train_y)
		predicted=clf.predict(test_x)
		auc.append(roc_auc_score(test_y, predicted))
		accu.append(accuracy_score(test_y, predicted))
		f1.append(f1_score(test_y,predicted))
	auc=mean(auc)
	accu=mean(accu)
	f1=mean(f1)
	prediction_dict["SVM"]=[auc, accu, f1 ]
	return prediction_dict

def RandomForest_model(X, y, sf, prediction_dict):

	auc=[]
	accu=[]
	f1=[]
	for train_ix , test_ix in sf.split(X, y):
		train_x, test_x = X[train_ix], X[test_ix]
		train_y, test_y = y[train_ix], y[test_ix]
		oversample=SMOTE()
		train_x,train_y=oversample.fit_resample(train_x, train_y)
		clf = RandomForestClassifier().fit(train_x, train_y)
		predicted=clf.predict(test_x)
		auc.append(roc_auc_score(test_y, predicted))
		accu.append(accuracy_score(test_y, predicted))
		f1.append(f1_score(test_y,predicted))
	auc=mean(auc)
	accu=mean(accu)
	f1=mean(f1)
	prediction_dict["RandomForest"]=[auc, accu, f1 ]
	return prediction_dict

def Logistic_model(X, y, sf,prediction_dict):

	auc=[]
	accu=[]
	f1=[]
	for train_ix , test_ix in sf.split(X, y):
		train_x, test_x = X[train_ix], X[test_ix]
		train_y, test_y = y[train_ix], y[test_ix]
		oversample=SMOTE()
		train_x,train_y=oversample.fit_resample(train_x, train_y)
		clf = LogisticRegression().fit(train_x, train_y)
		predicted=clf.predict(test_x)
		auc.append(roc_auc_score(test_y, predicted))
		accu.append(accuracy_score(test_y, predicted))
		f1.append(f1_score(test_y,predicted))
	auc=mean(auc)
	accu=mean(accu)
	f1=mean(f1)
	prediction_dict["Logistic Regression"]=[auc, accu, f1 ]
	return prediction_dict
def Knearest_model(X, y, sf ,prediction_dict):

	auc=[]
	accu=[]
	f1=[]
	for train_ix , test_ix in sf.split(X, y):
		train_x, test_x = X[train_ix], X[test_ix]
		train_y, test_y = y[train_ix], y[test_ix]
		oversample=SMOTE()
		train_x,train_y=oversample.fit_resample(train_x, train_y)
		clf = KNeighborsClassifier().fit(train_x, train_y)
		predicted=clf.predict(test_x)
		auc.append(roc_auc_score(test_y, predicted))
		accu.append(accuracy_score(test_y, predicted))
		f1.append(f1_score(test_y,predicted))
	auc=mean(auc)
	accu=mean(accu)
	f1=mean(f1)
	prediction_dict["Knearest Model"]=[ auc, accu, f1 ]
	return prediction_dict

def BalancedBagging_model(X, y,sf,prediction_dict):

	auc=[]
	accu=[]
	f1=[]
	for train_ix , test_ix in sf.split(X, y):
		train_x, test_x = X[train_ix], X[test_ix]
		train_y, test_y = y[train_ix], y[test_ix]
		oversample=SMOTE()
		train_x,train_y=oversample.fit_resample(train_x, train_y)
		clf = BalancedBaggingClassifier().fit(train_x, train_y)
		predicted=clf.predict(test_x)
		auc.append(roc_auc_score(test_y, predicted))
		accu.append(accuracy_score(test_y, predicted))
		f1.append(f1_score(test_y,predicted))
	auc=mean(auc)
	accu=mean(accu)
	f1=mean(f1)
	prediction_dict["Balanced Bagging"]=[ auc, accu, f1 ]
	return prediction_dict

def RUS_model(X, y, sf ,prediction_dict):

	auc=[]
	accu=[]
	f1=[]
	for train_ix , test_ix in sf.split(X, y):
		train_x, test_x = X[train_ix], X[test_ix]
		train_y, test_y = y[train_ix], y[test_ix]
		oversample=SMOTE()
		train_x,train_y=oversample.fit_resample(train_x, train_y)
		clf = RUSBoostClassifier().fit(train_x, train_y)
		predicted=clf.predict(test_x)
		auc.append(roc_auc_score(test_y, predicted))
		accu.append(accuracy_score(test_y, predicted))
		f1.append(f1_score(test_y,predicted))
	auc=mean(auc)
	accu=mean(accu)
	f1=mean(f1)
	prediction_dict["RUS"]=[auc, accu, f1 ]
	return prediction_dict

def  Training(all_features, all_labels):
	prediction_dict={}
	sf=StratifiedKFold(n_splits=3, random_state=1, shuffle=True)
	prediction_dict=svm_model(all_features, all_labels, sf, prediction_dict)
	prediction_dict=RandomForest_model(all_features, all_labels, sf, prediction_dict)
	prediction_dict=Logistic_model(all_features, all_labels,sf,prediction_dict)
	prediction_dict=Knearest_model(all_features, all_labels, sf, prediction_dict)
	prediction_dict=BalancedBagging_model(all_features, all_labels,sf, prediction_dict)
	prediction_dict=RUS_model(all_features, all_labels,sf, prediction_dict)

	l=prediction_dict.items()
	maximum=0
	model=""
	for item in l:
		if item[1][2]>maximum:
			maximum=item[1][2]
			model=item[0]
	print( "\n--- Training and Testing Completed ! ---\n")
	print("\n\nSelected Model: "+ model + " F1 score: " + str(maximum))
	return prediction_dict

# Ovarian Script
print( "->>> Running Model for Ovarian Cancer <<<-")

hub="https://tcga.xenahubs.net"
data_set_name="TCGA.OV.sampleMap/HumanMethylation27" # TGCA ovarian 27k
data_set_name_phenotype="TCGA.OV.sampleMap/OV_clinicalMatrix"

samples=get_samples(hub, data_set_name, 616)
features=get_features(hub, data_set_name)
data=get_data(hub, data_set_name, samples, features)
stages=get_label(hub, data_set_name_phenotype, samples, "clinical_stage")

stages, data, samples =handling_missing_values({'1':1,'2':0,'3':0,'4':1,'5':0,'6':0,'7':0,'8':0,'9':0,'10':0}, stages, data, samples)

scores_dict=Training(np.asarray(data), np.asarray( stages))
print(scores_dict)

#Kidney Clear Cell Carcinoma Script

print( "->>> Running Model for Kidney Clear Cell Carcinoma <<<-")

hub="https://gdc.xenahubs.net"
data_set_name="TCGA-KIRC.methylation27.tsv"
data_set_name_phenotype="TCGA-KIRC.GDC_phenotype.tsv"

samples=get_samples(hub, data_set_name, 414)
features=get_features(hub, data_set_name)
data=get_data(hub, data_set_name, samples, features)
stages=get_label(hub, data_set_name_phenotype, samples, "tumor_stage.diagnoses")

stages, data, samples =handling_missing_values({'1':0,'2':0,'3':1,'4':1}, stages, data, samples)
scores_dict=Training(np.asarray(data), np.asarray( stages))
print(scores_dict)